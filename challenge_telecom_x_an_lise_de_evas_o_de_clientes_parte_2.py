# -*- coding: utf-8 -*-
"""challenge-telecom-x-an-lise-de-evas-o-de-clientes-parte-2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/gist/Marcellecarol/edcde7202083bb87444c956061394ca9/challenge-telecom-x-an-lise-de-evas-o-de-clientes-parte-2.ipynb
"""

# üì¶ Importar bibliotecas
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score

sns.set(style="whitegrid")
plt.rcParams["figure.figsize"] = (12, 6)

# üîΩ Carregar dados JSON da URL oficial
url = "https://raw.githubusercontent.com/alura-cursos/challenge2-data-science/main/TelecomX_Data.json"
df = pd.read_json(url)
df.head()

# üõ†Ô∏è Expandir colunas aninhadas
df_customer = pd.json_normalize(df['customer'])
df_phone = pd.json_normalize(df['phone'])
df_internet = pd.json_normalize(df['internet'])
df_account = pd.json_normalize(df['account'])

# Combinar tudo
df_final = pd.concat([df[['customerID', 'Churn']], df_customer, df_phone, df_internet, df_account], axis=1)

# Padronizar colunas
df_final.columns = df_final.columns.str.lower().str.replace(' ', '_').str.replace('.', '_')
df_final.rename(columns={'customerid': 'customer_id', 'churn': 'churn'}, inplace=True)

# üéØ Convers√£o de tipos
df_final['charges_monthly'] = pd.to_numeric(df_final['charges_monthly'], errors='coerce')
df_final['charges_total'] = pd.to_numeric(df_final['charges_total'], errors='coerce')
df_final['tenure'] = pd.to_numeric(df_final['tenure'], errors='coerce')
df_final['seniorcitizen'] = pd.to_numeric(df_final['seniorcitizen'], errors='coerce')

# Preencher nulos
df_final['charges_total'] = df_final['charges_total'].fillna(df_final['charges_total'].median())

# Padronizar texto
cat_cols = df_final.select_dtypes(include='object').columns
for col in cat_cols:
    df_final[col] = df_final[col].str.lower().str.strip()

# Codificar vari√°vel alvo
df_final['churn'] = df_final['churn'].map({'yes': 'sim', 'no': 'n√£o'})
df_final['churn_bin'] = df_final['churn'].map({'sim': 1, 'n√£o': 0})

df_final.dropna(subset=['churn_bin'], inplace=True)

print("Valores √∫nicos em Churn original:", df['Churn'].unique())

df['Churn'] = df['Churn'].str.strip().str.lower()

# üîß Preparar dados para modelagem
X = df_final.drop(columns=['customer_id', 'churn', 'churn_bin'])
y = df_final['churn_bin']

X = pd.get_dummies(X, drop_first=True)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.3, random_state=42, stratify=y)

# ü§ñ Treinar modelos
lr = LogisticRegression(max_iter=1000)
dt = DecisionTreeClassifier(random_state=42)
rf = RandomForestClassifier(n_estimators=100, random_state=42)

lr.fit(X_train, y_train)
dt.fit(X_train, y_train)
rf.fit(X_train, y_train)

y_pred_lr = lr.predict(X_test)
y_pred_dt = dt.predict(X_test)
y_pred_rf = rf.predict(X_test)

# üìä Avaliar modelos
def avaliar_modelo(nome, y_true, y_pred):
    print(f"\nüìå {nome}")
    print(confusion_matrix(y_true, y_pred))
    print(classification_report(y_true, y_pred))
    print("ROC AUC Score:", roc_auc_score(y_true, y_pred))
    print("-" * 50)

avaliar_modelo("Regress√£o Log√≠stica", y_test, y_pred_lr)
avaliar_modelo("√Årvore de Decis√£o", y_test, y_pred_dt)
avaliar_modelo("Random Forest", y_test, y_pred_rf)

# üîç Import√¢ncia das vari√°veis (Random Forest)
importances = rf.feature_importances_
features = X.columns

importancia_df = pd.DataFrame({'feature': features, 'importance': importances})
importancia_df = importancia_df.sort_values(by='importance', ascending=False)

plt.figure(figsize=(12, 6))
sns.barplot(data=importancia_df.head(10), x='importance', y='feature')
plt.title('Top 10 vari√°veis mais influentes no Churn')
plt.show()

# ‚úÖ Conclus√µes finais
print("‚úÖ Conclus√µes:")
print("- Random Forest apresentou melhor desempenho.")
print("- As vari√°veis mais influentes no churn foram:")
print(importancia_df.head(5)['feature'].values)

"""Previs√£o de Churn em TelecomX
üìã Descri√ß√£o
Este projeto realiza uma an√°lise e modelagem preditiva para identificar clientes que provavelmente ir√£o cancelar (churn) o servi√ßo da empresa de telecomunica√ß√µes fict√≠cia TelecomX. Utilizando dados JSON com informa√ß√µes demogr√°ficas, de servi√ßo e conta, o objetivo √© construir modelos que ajudem a prever o churn com boa acur√°cia.

üóÇÔ∏è Dados
Os dados foram obtidos de uma fonte p√∫blica no formato JSON, contendo informa√ß√µes aninhadas sobre clientes, telefone, internet e conta:

customer: dados demogr√°ficos do cliente (g√™nero, dependentes, tempo como cliente, etc.)

phone: servi√ßos telef√¥nicos contratados

internet: servi√ßos de internet contratados

account: informa√ß√µes de pagamento e contratos

churn: vari√°vel alvo indicando se o cliente cancelou ou n√£o

‚öôÔ∏è Tecnologias e Bibliotecas
Python 3.x

pandas

numpy

seaborn

matplotlib

scikit-learn

üöÄ Passos do projeto
Carregamento e prepara√ß√£o dos dados

Leitura dos dados JSON da URL

Expans√£o das colunas aninhadas com pd.json_normalize

Combina√ß√£o dos dados em um DataFrame √∫nico

Padroniza√ß√£o dos nomes das colunas e tipos de dados

Tratamento de valores faltantes e normaliza√ß√£o textual

Engenharia de dados

Codifica√ß√£o da vari√°vel alvo (churn) para valores bin√°rios

One-hot encoding para vari√°veis categ√≥ricas

Escalonamento dos dados num√©ricos

Modelagem

Separa√ß√£o dos dados em treino e teste (30% teste)

Treinamento de tr√™s modelos:

Regress√£o Log√≠stica

√Årvore de Decis√£o

Random Forest

Avalia√ß√£o

An√°lise de m√©tricas: matriz de confus√£o, relat√≥rio de classifica√ß√£o e ROC AUC

Visualiza√ß√£o das 10 vari√°veis mais importantes no modelo Random Forest

üìä Resultados
O modelo Random Forest apresentou o melhor desempenho para prever churn. As vari√°veis mais importantes foram exibidas em gr√°fico e listadas no final do c√≥digo.


"""